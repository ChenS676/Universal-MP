{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setting: On the impact of features orthogonality for Link Representation Learning with Message Passing Neural Network(MPNN)\n",
    "This experiment aims to analyze the capacity of MPNNs to capture structural features under varying configurations, including the type of MPNN, the node features employed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1\n",
    "\n",
    "1. Simplified MPNN: is a mapping from $f(\\tilde{\\mathbf{A}}, \\mathbf{X}) \\to \\mathbf{H}$, $\\text{softmax}(\\text{Act}((\\mathbf{\\tilde{A}XW^0)W^1}))$.\n",
    "    - $\\mathbf{h_i} \\in \\mathbb{R}^{d}$, embedding of vertex $i$, $n$: number of vertex, $d$ number of dimension.\n",
    "    - $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$: initial node features\n",
    "    - $\\mathbf{H}^*$: optimized node embedding w.r.t. all $\\mathbf{W}$\n",
    "    - $\\text{Act}$: Activation function, mostly nonlinear and [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)). \n",
    "    \n",
    "\n",
    "2. Loss Function: $\\argmin_{H^*}  \\underbrace{\\sum_{(i,j) \\in E_\\text{pos}} \\Vert 1 - \\sigma(h_i, h_j)^\\top \\Vert_2^2}_{\\text{positive samples}} + \\underbrace{\\sum_{(i,j) \\in E_{\\text{neg}}} \\Vert (0 - \\sigma(h_i, h_j)^\\top \\Vert)_2^2}_{\\text{negative samples}}$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "root = '/pfs/work7/workspace/scratch/cc7738-kdd25/Universal-MP/trials/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store DataFrames\n",
    "def merge_csv_files(results_dir, output_file, key):\n",
    "    dataframes = []\n",
    "    results_dir = root + results_dir\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(results_dir):\n",
    "        if filename.endswith(f\"{key}.csv\"):  # Check if file ends with 'CN_ddi.csv'\n",
    "            file_path = os.path.join(results_dir, filename)\n",
    "            print(f\"Loading file: {file_path}\")\n",
    "            df = pd.read_csv(file_path)  # Read the CSV file\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    if dataframes:\n",
    "        merged_ppr = pd.concat(dataframes, ignore_index=True)\n",
    "        # Group by 'Model' and 'NodeFeat' and calculate mean and variance\n",
    "        stats = merged_ppr.groupby(['Model', 'NodeFeat'])['Test_Loss'].agg(['mean', 'var']).reset_index()\n",
    "\n",
    "        stats.to_csv(output_file, index=False)\n",
    "        print(f\"Merged {len(dataframes)} files into {output_file}\")\n",
    "    else:\n",
    "        print(\"No files ending with 'PPR_ddi.csv' found in the directory.\")\n",
    "    return merged_ppr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data values from the merged statistics\n",
    "def plot_result(df):\n",
    "\n",
    "    # Group and process the data\n",
    "    result = df.groupby(['Model', 'NodeFeat'])['Test_Loss'].agg(['mean', 'var']).reset_index()\n",
    "    result.columns = ['Model', 'NodeFeat', 'Mean_Test_Loss', 'Variance_Test_Loss']\n",
    "\n",
    "    # Handle non-positive variance\n",
    "    result['Variance_Test_Loss'] = result['Variance_Test_Loss'].apply(lambda x: x if x > 0 else 1e-9)\n",
    "\n",
    "    # Unique models and features\n",
    "    unique_models = result['Model'].unique()\n",
    "    unique_features = result['NodeFeat'].unique()\n",
    "\n",
    "    # Define colors\n",
    "    colors = ['#fbb4ae', '#b3cde3', '#ccebc5', '#decbe4', '#fed9a6']\n",
    "\n",
    "    # Define plot settings\n",
    "    width = 0.15  # Width of each bar\n",
    "    x = np.arange(len(unique_models))  # X positions for the models\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    for i, feature in enumerate(unique_features):\n",
    "        feature_data = result[result['NodeFeat'] == feature]\n",
    "        values = feature_data['Mean_Test_Loss'].values\n",
    "        errors = np.sqrt(feature_data['Variance_Test_Loss'].values)  # Standard deviation for error bars\n",
    "\n",
    "        # Plot bar with error bars\n",
    "        ax.bar(x + i * width, values, width, yerr=errors, label=feature, color=colors[i % len(colors)], capsize=5)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_ylabel('Mean Test Loss')\n",
    "    ax.set_title('Mean and Variance of Test Loss for Common Neighbor Across Models', loc='center', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x + width * (len(unique_features) - 1) / 2)\n",
    "    ax.set_xticklabels(unique_models)\n",
    "    ax.legend(loc='upper right', title=\"Feature Type\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the files\n",
    "results_dir = \"results/ddi\"\n",
    "output_file = \"merged_CN_ddi.csv\"\n",
    "\n",
    "merged_cn = merge_csv_files(\"results/ddi\", \"merged_CN_ddi.csv\", \"CN_ddi\")\n",
    "print(merged_cn)\n",
    "img = plot_result(merged_cn)\n",
    "img.savefig('CN_ddi.png')\n",
    "\n",
    "merged_ppr = merge_csv_files(\"results/ddi\", \"merged_PPR_ddi.csv\", \"PPR_ddi\")\n",
    "print(merged_ppr)\n",
    "img = plot_result(merged_ppr)\n",
    "img.savefig('PPR_ddi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ppr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T01:30:37.239709Z",
     "start_time": "2024-11-11T01:30:37.040429Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data values from the merged statistics\n",
    "\n",
    "def plot_result(df):\n",
    "    # Plot settings\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    x = np.arange(len(df[\"Model\"].unique()))  # x-axis positions for each method\n",
    "    width = 0.15  # Adjusted width for additional feature type\n",
    "\n",
    "    colors = ['#fbb4ae', '#b3cde3', '#ccebc5', '#decbe4', '#fed9a6']  # Soft pastel shades\n",
    "\n",
    "    unique_features = df[\"NodeFeat\"].unique()\n",
    "    methods = df[\"Model\"].unique()\n",
    "\n",
    "    complete_index = pd.MultiIndex.from_product([methods, unique_features], names=[\"Model\", \"NodeFeat\"])\n",
    "    df = df.set_index([\"Model\", \"NodeFeat\"]).reindex(complete_index, fill_value=0).reset_index()\n",
    "\n",
    "    for i, feature in enumerate(unique_features):\n",
    "        feature_data = df[df[\"NodeFeat\"] == feature]\n",
    "        values = feature_data[\"Mean_Loss\"].values\n",
    "        errors = np.sqrt(feature_data[\"Variance_Loss\"].values)  # Standard deviation for error bars\n",
    "\n",
    "        # Plot bar with error bars\n",
    "        ax.bar(x + i * width, values, width, yerr=errors, label=feature, color=colors[i], capsize=5)\n",
    "\n",
    "        # Adding data labels for mean values\n",
    "        for j, val in enumerate(values):\n",
    "            ax.text(x[j] + i * width, val + 0.001, f'{val:.3f}', ha='center', va='bottom')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_ylabel('Mean Test Loss')\n",
    "    ax.set_title('Mean and Variance of Test Loss for Common Neighbor Across Models', loc='center', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x + width * (len(unique_features) - 1) / 2)\n",
    "    ax.set_xticklabels(methods)\n",
    "    ax.legend(loc='upper right', title=\"Feature Type\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GCN \n",
    "$\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{W}$\n",
    "\n",
    "$\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}$ denotes the adjacency matrix with inserted self-loops and \n",
    "$\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}$ its diagonal degree matrix.\n",
    "\n",
    "$    \\mathbf{x}^{\\prime}_i = \\mathbf{W}^{\\top} \\sum_{j \\in\n",
    "    \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{e_{j,i}}{\\sqrt{\\hat{d}_j\n",
    "    \\hat{d}_i}} \\mathbf{x}_j $\n",
    "\n",
    "$\\hat{d}_i = 1 + \\sum_{j \\in \\mathcal{N}(i)} e_{j,i}$, where $e_{j,i}$ denotes the edge weight from source node `j` to target node `i` (default: `1.0`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGE \n",
    "$\\mathbf{x}^{\\prime}_i = \\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{W}_2 \\cdot\n",
    "    \\mathrm{mean}_{j \\in \\mathcal{N(i)}} \\mathbf{x}_j $\n",
    "\n",
    "\n",
    "$    \\mathbf{x}_j \\leftarrow \\sigma ( \\mathbf{W}_3 \\mathbf{x}_j +\n",
    "    \\mathbf{b}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIN\n",
    "$\\mathbf{x}^{\\prime}_i = h_{\\mathbf{\\Theta}} \\left( (1 + \\epsilon) \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{j \\in \\mathcal{N}(i)} \\mathrm{ReLU}\n",
    "        ( \\mathbf{x}_j + \\mathbf{e}_{j,i} ) \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINKX\n",
    "$\\mathbf{H}_{\\mathbf{A}} = \\text{MLP}_{\\mathbf{A}}(\\mathbf{A})$\n",
    "\n",
    "$\\mathbf{H}_{\\mathbf{X}} = \\textrm{MLP}_{\\mathbf{X}}(\\mathbf{X})$\n",
    "\n",
    "$\\mathbf{Y} = \\textrm{MLP}_{f} \\left( \\sigma \\left( \\mathbf{W}\n",
    "[\\mathbf{H}_{\\mathbf{A}}, \\mathbf{H}_{\\mathbf{X}}] +\n",
    "\\mathbf{H}_{\\mathbf{A}} + \\mathbf{H}_{\\mathbf{X}} \\right) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T01:30:37.252141Z",
     "start_time": "2024-11-11T01:30:37.240511Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_result(merged_ppr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAG-LP_g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
