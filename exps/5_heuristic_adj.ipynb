{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Javascript\n",
    "import json\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/hkfs/work/workspace/scratch/cc7738-subgraph_training/Universal-MP')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "from graphgps.utils.ogbdataset import loaddataset\n",
    "from graphgps.utils.heuristic import CN, AA, RA\n",
    "from graphgps.models.GNN import GAT_Variant, GCN_Variant, SAGE_Variant, GIN_Variant, GAE_forall, InnerProduct, mlp_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "categories = ['C.ele', 'USAir', 'E.coli', 'Yeast', 'PB', 'NS', 'Power', 'Router']\n",
    "methods = ['Baseline', 'GCN', 'SAGE', 'SEAL']\n",
    "metrics = ['CN', 'AA', 'RA']\n",
    "data = {\n",
    "    'CN': np.random.rand(4, len(categories)) * 100,  # Simulated data\n",
    "    'AA': np.random.rand(4, len(categories)) * 10,\n",
    "    'RA': np.random.rand(4, len(categories)) * 1\n",
    "}\n",
    "errors = {\n",
    "    'CN': np.random.rand(4, len(categories)) * 10,\n",
    "    'AA': np.random.rand(4, len(categories)) * 1,\n",
    "    'RA': np.random.rand(4, len(categories)) * 0.1\n",
    "}\n",
    "\n",
    "# Plot settings\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 6), sharex=True)\n",
    "x = np.arange(len(categories))  # x-axis positions for each category\n",
    "width = 0.2  # Width of each bar\n",
    "\n",
    "# Colors for each method\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    for j, method in enumerate(methods):\n",
    "        ax.bar(x + j * width, data[metric][j], width, label=method, yerr=errors[metric][j], color=colors[j])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('MSE')\n",
    "    ax.set_title(metric, loc='left', fontsize=12, backgroundcolor='wheat', fontweight='bold')\n",
    "    ax.grid(True, which=\"both\", linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Set labels and legend\n",
    "axes[-1].set_xticks(x + width * 1.5)\n",
    "axes[-1].set_xticklabels(categories)\n",
    "axes[0].legend(methods, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GNNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GAE_model(cfg_model: CN,\n",
    "                     cfg_score: CN,\n",
    "                     model_name: str):\n",
    "    if model_name in {'GAT', 'VGAE', 'GAE', 'GraphSage'}:\n",
    "        raise NotImplementedError('Current model does not exist')\n",
    "        # model = create_model(cfg_model)\n",
    "\n",
    "    elif model_name == 'GAT_Variant':\n",
    "        encoder = GAT_Variant(cfg_model.in_channels,\n",
    "                              cfg_model.hidden_channels,\n",
    "                              cfg_model.out_channels,\n",
    "                              cfg_model.num_layers,\n",
    "                              cfg_model.dropout,\n",
    "                              cfg_model.heads,\n",
    "                              )\n",
    "    elif model_name == 'GCN_Variant':\n",
    "        encoder = GCN_Variant(cfg_model.in_channels,\n",
    "                              cfg_model.hidden_channels,\n",
    "                              cfg_model.out_channels,\n",
    "                              cfg_model.num_layers,\n",
    "                              cfg_model.dropout,\n",
    "                              )\n",
    "    elif model_name == 'SAGE_Variant':\n",
    "        encoder = SAGE_Variant(cfg_model.in_channels,\n",
    "                               cfg_model.hidden_channels,\n",
    "                               cfg_model.out_channels,\n",
    "                               cfg_model.num_layers,\n",
    "                               cfg_model.dropout,\n",
    "                               )\n",
    "    elif model_name == 'GIN_Variant':\n",
    "        encoder = GIN_Variant(cfg_model.in_channels,\n",
    "                              cfg_model.hidden_channels,\n",
    "                              cfg_model.out_channels,\n",
    "                              cfg_model.num_layers,\n",
    "                              cfg_model.dropout,\n",
    "                              cfg_model.mlp_layer\n",
    "                              )\n",
    "    if cfg_score.product == 'dot':\n",
    "        decoder = mlp_score(cfg_model.out_channels,\n",
    "                            cfg_score.score_hidden_channels,\n",
    "                            cfg_score.score_out_channels,\n",
    "                            cfg_score.score_num_layers,\n",
    "                            cfg_score.score_dropout,\n",
    "                            cfg_score.product)\n",
    "    elif cfg_score.product == 'inner':\n",
    "        decoder = InnerProduct()\n",
    "\n",
    "    else:\n",
    "        # Without this else I got: UnboundLocalError: local variable 'model' referenced before assignment\n",
    "        raise ValueError('Current model does not exist')\n",
    "\n",
    "    return GAE_forall(encoder=encoder, decoder=decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(file_path, model_name, heuristic, test_loss):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Model', 'Heuristic', 'Test_Loss'])\n",
    "        writer.writerow([model_name, heuristic, test_loss])\n",
    "        \n",
    "def visualize(pred, true_label, save_path = './visualization.png'):\n",
    "\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "    true_label = true_label.cpu().detach().numpy()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(np.arange(len(true_label)), true_label, color='blue', label='True Score', alpha=0.6)\n",
    "    plt.scatter(np.arange(len(pred)), pred, color='red', label='Prediction', alpha=0.6)\n",
    "\n",
    "    plt.title('Predictions vs True Score')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Visualization saved at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data, splits, device, epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Positive and negative edges for training\n",
    "    pos_edge_index = splits['train']['pos_edge_label_index'].to(device)\n",
    "    neg_edge_index = splits['train']['neg_edge_label_index'].to(device)\n",
    "\n",
    "    # Labels for positive and negative edges (continuous regression labels)\n",
    "    pos_edge_label = splits['train']['pos_edge_score'].to(device)\n",
    "    neg_edge_label = splits['train']['neg_edge_score'].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "    # Compute predictions for both positive and negative edges\n",
    "    pos_pred = model.decode(z[pos_edge_index[0]], z[pos_edge_index[1]])\n",
    "    neg_pred = model.decode(z[neg_edge_index[0]], z[neg_edge_index[1]])\n",
    "\n",
    "    # Compute regression loss (MSE for continuous labels)\n",
    "    pos_loss = F.mse_loss(pos_pred, pos_edge_label)\n",
    "    neg_loss = F.mse_loss(neg_pred, neg_edge_label)\n",
    "    loss = pos_loss + neg_loss\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "    visualize(pos_pred, pos_edge_label, save_path='./visualization_pos_train.png')\n",
    "    visualize(neg_pred, neg_edge_label, save_path='./visualization_neg_train.png')\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid(model, data, splits, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    # Positive and negative edges for validation\n",
    "    pos_edge_index = splits['valid']['pos_edge_label_index'].to(device)\n",
    "    neg_edge_index = splits['valid']['neg_edge_label_index'].to(device)\n",
    "\n",
    "    # Labels for positive and negative edges (continuous regression labels)\n",
    "    pos_edge_label = splits['valid']['pos_edge_score'].to(device)\n",
    "    neg_edge_label = splits['valid']['neg_edge_score'].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "    # Predict scores for both positive and negative edges\n",
    "    pos_pred = model.decode(z[pos_edge_index[0]], z[pos_edge_index[1]])\n",
    "    neg_pred = model.decode(z[neg_edge_index[0]], z[neg_edge_index[1]])\n",
    "\n",
    "    # Compute regression loss (MSE)\n",
    "    pos_loss = F.mse_loss(pos_pred, pos_edge_label)\n",
    "    neg_loss = F.mse_loss(neg_pred, neg_edge_label)\n",
    "    loss = pos_loss + neg_loss\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, splits, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Positive and negative edges for test\n",
    "    pos_edge_index = splits['test']['pos_edge_label_index'].to(device)\n",
    "    neg_edge_index = splits['test']['neg_edge_label_index'].to(device)\n",
    "\n",
    "    # Labels for positive and negative edges (continuous regression labels)\n",
    "    pos_edge_label = splits['test']['pos_edge_score'].to(device)\n",
    "    neg_edge_label = splits['test']['neg_edge_score'].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "    # Predict scores for both positive and negative edges\n",
    "    pos_pred = model.decode(z[pos_edge_index[0]], z[pos_edge_index[1]])\n",
    "    neg_pred = model.decode(z[neg_edge_index[0]], z[neg_edge_index[1]])\n",
    "    visualize(pos_pred, pos_edge_label, save_path = './visualization_pos.png')\n",
    "    visualize(neg_pred, neg_edge_label, save_path = './visualization_neg.png')\n",
    "\n",
    "    # Compute regression loss (MSE)\n",
    "    pos_loss = F.mse_loss(pos_pred, pos_edge_label)\n",
    "    neg_loss = F.mse_loss(neg_pred, neg_edge_label)\n",
    "    loss = pos_loss + neg_loss\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.epochs = 30\n",
    "        self.dataset = \"Cora\"\n",
    "        self.batch_size = 512\n",
    "        self.heuristic = \"AA\"\n",
    "        self.gnn = \"gcn\"\n",
    "        self.model = \"GIN_Variant\"\n",
    "        self.use_feature = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hkfs/work/workspace/scratch/cc7738-subgraph_training/Universal-MP/graphgps/utils/heuristic.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  multiplier = 1 / np.log(A.sum(axis=0))\n",
      "/hkfs/work/workspace/scratch/cc7738-subgraph_training/Universal-MP/graphgps/utils/heuristic.py:24: RuntimeWarning: divide by zero encountered in divide\n",
      "  multiplier = 1 / np.log(A.sum(axis=0))\n",
      "/home/hk-project-test-p0021478/cc7738/anaconda3/envs/TAG-LP/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers in gin:  1\n",
      "layers in mlp:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_2006399/159136271.py:21: UserWarning: Using a target size (torch.Size([4224])) that is different to the input size (torch.Size([4224, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  pos_loss = F.mse_loss(pos_pred, pos_edge_label)\n",
      "/scratch/ipykernel_2006399/159136271.py:22: UserWarning: Using a target size (torch.Size([4224])) that is different to the input size (torch.Size([4224, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  neg_loss = F.mse_loss(neg_pred, neg_edge_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 001, Loss: 0.0191\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 002, Loss: 0.0188\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 003, Loss: 0.0185\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 004, Loss: 0.0182\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 005, Loss: 0.0180\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 006, Loss: 0.0178\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 007, Loss: 0.0177\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 008, Loss: 0.0175\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 009, Loss: 0.0174\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 010, Loss: 0.0173\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 011, Loss: 0.0172\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 012, Loss: 0.0172\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 013, Loss: 0.0171\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 014, Loss: 0.0171\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 015, Loss: 0.0171\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 016, Loss: 0.0170\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 017, Loss: 0.0170\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 018, Loss: 0.0169\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 019, Loss: 0.0168\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 020, Loss: 0.0168\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 021, Loss: 0.0167\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 022, Loss: 0.0166\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 023, Loss: 0.0165\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 024, Loss: 0.0165\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 025, Loss: 0.0164\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 026, Loss: 0.0163\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 027, Loss: 0.0162\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 028, Loss: 0.0162\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 029, Loss: 0.0161\n",
      "Visualization saved at ./visualization_pos_train.png\n",
      "Visualization saved at ./visualization_neg_train.png\n",
      "Epoch: 030, Loss: 0.0160\n",
      "Visualization saved at ./visualization_pos.png\n",
      "Visualization saved at ./visualization_neg.png\n",
      "Saved results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_2006399/159136271.py:83: UserWarning: Using a target size (torch.Size([791])) that is different to the input size (torch.Size([791, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  pos_loss = F.mse_loss(pos_pred, pos_edge_label)\n",
      "/scratch/ipykernel_2006399/159136271.py:84: UserWarning: Using a target size (torch.Size([791])) that is different to the input size (torch.Size([791, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  neg_loss = F.mse_loss(neg_pred, neg_edge_label)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = Config()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, splits = loaddataset(args.dataset, True)\n",
    "data = data.to(device)\n",
    "\n",
    "\n",
    "with open('/hkfs/work/workspace/scratch/cc7738-subgraph_training/Universal-MP/yamls/cora/heart_gnn_models.yaml', \"r\") as f:\n",
    "    cfg = CfgNode.load_cfg(f)\n",
    "    \n",
    "cfg_model = eval(f'cfg.model.{args.model}')\n",
    "if not hasattr(splits['train'], 'x') or splits['train'].x is None:\n",
    "    cfg_model.in_channels = 1024\n",
    "else:\n",
    "    cfg_model.in_channels = data.num_nodes\n",
    "cfg_score = eval(f'cfg.score.{args.model}')\n",
    "cfg.model.type = args.model\n",
    "edge_weight = torch.ones(data.edge_index.size(1), dtype=float)\n",
    "A = ssp.csr_matrix(\n",
    "    (edge_weight, (data.edge_index[0].cpu(), data.edge_index[1].cpu())),\n",
    "    shape=(data.num_nodes, data.num_nodes)\n",
    ")\n",
    "method_dict = {\n",
    "    \"CN\": CN,\n",
    "    \"AA\": AA,\n",
    "    \"RA\": RA\n",
    "}\n",
    "for split in splits:\n",
    "    pos_edge_score, _ = method_dict[args.heuristic](A, splits[split]['pos_edge_label_index'],\n",
    "                                                    batch_size=args.batch_size)\n",
    "    neg_edge_score, _ = method_dict[args.heuristic](A, splits[split]['neg_edge_label_index'],\n",
    "                                                    batch_size=args.batch_size)\n",
    "    splits[split]['pos_edge_score'] = torch.sigmoid(pos_edge_score)\n",
    "    splits[split]['neg_edge_score'] = torch.sigmoid(neg_edge_score)\n",
    "if not args.use_feature:\n",
    "    A_dense = A.toarray()\n",
    "    A_tensor = torch.tensor(A_dense)\n",
    "    data.x = A_tensor.float().to(device)\n",
    "\n",
    "model = create_GAE_model(cfg_model, cfg_score, args.model).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    start = time.time()\n",
    "    loss = train(model, optimizer, data, splits, device, args.batch_size)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "test_loss = test(model, data, splits, device)\n",
    "save_to_csv(f'./results/test_results_{args.dataset}.csv', args.model, args.heuristic, test_loss)\n",
    "print('Saved results.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAG-LP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
